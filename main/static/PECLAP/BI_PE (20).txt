INTRODUCTION
It is acknowledged that an intelligent data analysis can provide great value for both scientific and commercial fields. The interpretation of data analysis results gives an opportunity to achieve significant knowledge, which in turn can be used to make crucial business decisions in different domains: marketing, medicine, management, economics etc. But to conduct any kind of data analysis it is needed to complete a process known as data mining. Data mining is defined as the process of extracting useful information. Basically, it is the process of discovering hidden patterns and information from existing data. By using techniques like clustering, classification, association and regression, data scientists extract useful data, patterns and trends from a large amount of data. The task of discovering hidden knowledge in data has never been more relevant than now. Big corporations measure risks in knowledge gained from datamining, scientific progress is made by carefully examining the evidence provided by data scientists. 
More and more algorithms are being developed to handle various tasks in this field. This is due to the fact that datamining tasks are differ greatly from case to case, and each of them requires individual approach to gain most fruitful results. Because of that, modern datamining applications have wide variety of tools to handle different tasks. The problem is that data scientists have to work with only what the developers of applications provide, without the ability to create and implement their own solutions for specific tasks.
The need to configure and customize different algorithms leads to the idea of creating a flexible, modular architecture for an application that performs intelligent data analysis. Creation of such architecture is the essence of this work.
LITERATURE REVIEW
There are two main techniques to interpret machine learning: supervised an unsupervised learning. Supervised machine learning comes with a provision of already labeled data, from which the algorithm can be trained to predict the future similar data. This allows predicting either the "class" of data or its dynamics (trends). 
One of the branches of data mining is known as Subgroup Discovery. The subgroup discovery approach is based on identifying the descriptive characteristics of subgroups in the dataset that show interesting (according to selected quality criteria) relationships in comparison with other subgroups of the same dataset. Discovering subgroups make it possible to highlight, for example, general information about dependencies in the dataset for both exploratory data analysis and predictive modelling.  
Subgroup discovery is based on the idea of local exceptionality detection, i.e., how locally exceptional, relevant and thus interesting patterns can be detected, so-called nuggets in the data. One of subgroup discovery's major advantages lies in its flexibility. This approach has numerous sophisticated algorithms, which all can be used to solve distinct research tasks. Methods of subgroup detection are used, for example, in the analysis of data from smart meters, error analysis of production processes, etc. As mentioned earlier, in order to apply these approaches, it is necessary to take into account that each data set has a different structure and, as a result, it is necessary to select different algorithms to obtain a quality result. 
To create a system for implementing data mining algorithms, it is needed to create an architecture which supports configuration of existing algorithms and can be used correctly when new algorithms are created and incorporated. Now, there exists a few applications designed specifically for data mining. These include RapidMiner, a popular data mining framework for extracting, modeling and transforming data, Orange - a platform with a similar instruments, but with its functionality leaning towards a toolbox than a complete data analysis framework and many others: UIMA, Apache Mahout, R Software Environment etc.   
These applications are great for both exploratory data analysis and have a wide array of solutions for different tasks, but they do not support the insertion of custom-made models and are not written in any beginner popular programming language. For example, C# or Python would be a much better language for a low-experienced programmer to begin his ventures in machine learning sphere due to its simplicity and familiarity.  
PROBLEM STATEMENT	
Data mining is an iterative process - not many analysts can conduct their assessment first try. Lots of things need to be taken into consideration: dataset's size, quantity of variables, quality of given data, and many more. First chosen algorithm may give unsatisfying results, and the work needs to start over again. Data scientist must write new, specific algorithms for given dataset, change hyperparameters and, in some cases, clean data yet again. This leads to time loss, and sequential reduce in profits. 
The solution to that problem would be to create an environment which supports configuration and substitutability of existing algorithms. This approach can reduce the time needed to complete the research and simplify the process of trying different algorithms. 
OBJECTIVES AND AIMS
To achieve the project goal - implementing a flexible, module-based architecture for Data Mining, the following objectives must be completed:
1. Analyze existing research in the areas of subgroup discovery and Pattern Mining, as well as analysis of formal concepts and pattern structures. 
2. Analyze existing open access applications for Data Mining in order to identify good practices in implementation.
3. Design the architecture of the application with the ability to add additional modules, as well as considering the features of the object-oriented language C#.
4. Develop a system with structure that supports the interchangeability of algorithms (modules). 
5. Implement existing Data Mining algorithms in the form of modules with open source code.
METHODS
In order to develop a system with goal of having interchangeable modules, the program needs to have a way to dynamically process context of given dataset. This can be achieved through defining an in-code interface for all the modules to implement and putting it into an assembly shared both for the program and modules. Implementors can write their own modules as inherited from the original interface, allowing for simple future maintainability and feature expansion. 
The starting point for datamining would be creation of a settings file, in which the analyst will specify parameters for algorithm: such as path to dataset file, target values file, and hyperparameters. JSON file type would be suitable for these files - they allow flexibility in their structure and are simple to reshape in accordance to task. 
The architecture itself will be designed using UML notation. Wide variety of different diagrams will allow for clarity in showing business processes of datamining system.
In order to increase student's interest in data science field, the C# programming language will be used. HSE students are most familiar with this language - it is primary studied in Business-Informatics and Software Engineering educational courses. Since the software will be developed in object-oriented language C#, the JSON.net framework can be used for parsing, serializing and deserializing the JSON files.
RESULTS ANTICIPATED
The result of this research would be a datamining application which supports module-based algorithm interchangeability. Based on given parameters in appropriate JSON file, the program will create a new instance of corresponding algorithm to be used in conjunction with dataset - with focus on getting valuable knowledge. 
The application could have additional features, such as interactive mode - ability to give user a choice in conducted mining process. Although graphic user interface would be a beneficial addition to this system, it would take considerable time to develop, leaving little for implementing the core features. This, however, can be added in future iteration after project is completed.
CONCLUSION
To this day, there are implementations of a platform for data analysis, but not many applications consider possible extensibility of the algorithms. The value of this study is linked to several factors:
* A flexible architecture will create an application that will allow empirical research, testing of different analysis methods and evaluation of results without necessity of changing datamining tools.
* When new datamining methods are discovered, it will not be difficult to add their implementation to an existing application.
Creating such a platform in a popular programming language will fill this niche, increase students' interest in data analysis and lay the foundation for a powerful tool for data analysis. 
