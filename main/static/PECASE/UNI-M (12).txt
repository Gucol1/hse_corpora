 can you hear yes can and hello dear colleagues let thank you for coming today name I'm fourth year student from higher school economics Perm and the topic I'm going discuss the civil liability for damage caused the artificial intelligence next and discussed detail about issue differentiation (eh) engineers and operator civil liability research relevant those who deal with issues and start process digitalization whole research based general research methods such analysis synthesis and comparison and (eh) interdisciplinary one. the formal legal research method so the slide you can see the main parts my study (eh) begin with will present the background civil liability for the actions AI then formulate the aim and objectives and then demonstrate the sources the study .after that will review the basic concepts AI study (eh) next will elaborate the problem differentiations AI engineers and operators liability autonomous systems and finally will discuss the results and make conclusion though (eh) it's well known fact that the development high technologies (eh) outpaces legal regulations. recent decades however these issue have been discussed more often for example the CCRN (eh) journal website published more than 1000 (eh) scientific papers AI the last year only in twenty seventeen the European Parliament parliament adopted resolution civil law robotics which sets out the main directions and principles for the development AI despite humanity at the beginning the past digitalization and significant objective the development legal mechanism regulate liability for damage caused AI and one the main question (eh) who brings the liability for the actions AI precise issue (eh) allocation (eh) liability between the operator and the engineers so will try answer these questions my report ... so. the slide you can see aim and the objectives don't comment. you can see ... and this slide you can see sources the study (eh) there are divided into international national and foreign (eh) acts and. domestic and foreign doctr legal doctrine (eh) undoubtedly the resolution your commission (eh) of particular importance of. for this study taking its provision into account the August twenty twenty the Russian government approves the concept the .for the development AI technology and robotics until twenty twenty four where one the main objectives the issue AI liability among doctrinal issues sources can emphasize studies German Professor Wagner liability AI engineers and Dutch scientists brought an intent the liability the operator having analyzed scientific papers (eh) various legal scholars can defined technology that has certain degree autonomy autonomy and able perform (eh) to precise imitate rational actions like human beings usually can self learn (eh) and may have (eh) material shell for example (eh) the form (eh) robot (eh) there debate doctrine (eh) concerning the legal personality (eh) AI believe that an object circulation (erm) the present time but cannot ignore that fact that may become cozy subject the near future particular this position held the researchers and others ... (eh) Israel professor the defiant four types subjects liability for the actions AI the manufacture the same the engineer the operator the distributor and the end user professor proposes the sponsor AI research subject liability based act the South Korean law smart robots and professor also supplements this list the owner and possessor but overall this list the subject not executive exhaustive (eh) according the (eh) euro commission's resolution nevertheless particular situations is important identify (eh) those person who should held liable for this actions the (em) speaking approaches civil (eh) liability for the actions different approaches are distinguished depending the classification. professor Smith and Neznamov distinguished seven types liability based degree culpability for such and suggest that liability I should considered through the concept legal person and however decided stop the classification based the responsibility subject responsibility here engineers while the researchers brought John Linton highlight the liability apparatus separate subject in the following look the basis for the allocation development operator liability professor defines that developer person who has taken part the development production autonomous systems including software developers the scientists believe that developer only person who able minimize. the risk because they are responsible for implementing precautions the use autonomous device and have more information than consumers based the European Commission Directive Product Liability they also points out that article for the burden proving defect lies with the consumer the case AI these allegations the burden proof seems unacceptable because would more difficult for the consumers prove (eh) defect specific products such AI they not have their current information about the object thus the consumer will not able cope with that burden proof that also proposed shift its to the developer .there also the position that fault liability also known strict liability should applied (eh) the developer (eh). the developer would liable for any damages other than guilty acts the consumer. our view the abrupt shifts such approach would destroy the entire scientific and technical potential AI system development the object discussion has been (eh) the imposition liability the operator .and that scientist defined the operator the person who provides updates and support services the autonomous device regular basis they are responsible for teaching the autonomous system they are informally called the teacher the first challenges that arise here what extend the teacher liable (eh) for opposed the engineer is logical us differentiate the liability establishing (eh) the obligation the former and the latter legal act contract however possible that developer and teacher may the same person (eh) the case (eh) wants distinguish liability for. designing the system from one it the second issue the distinguish between strict and limited liability scientists believe that strict liability applicable the situation where the amount damages caused significant the objects operate and public spaces has and has high degree autonomy .in cases AI treatment system for autism for example the amount potential damage not significant and is controlled operator it would wouldn't (eh) appropriate apply strict liability teacher particular situation however even this case where damage caused due defect (eh) the system itself strict liability permissible and those the I engineers and teachers liability are similar the first site but the engineers areas liability wider and consequently stricter standard liability should applied them they least have more information about the products the other hand the situation where the systems are evolving it's important not create unnecessary legal barriers the development such system the application strict liability should reasonable justified. and the last one teacher. liability separate subject applicable situations where I does not have high degree autonomy however the issue the liability self-loading whose actions beyond the control the engineers and the teacher remains unexplored. all things considered while systems continue evolve is important bear mind the development law order provide ways minimizing the potential damage that new technologies can cause thank you for your attention look forward answering your questions dear participants you are welcome with your questions ... (eh) the prospects for the prospects your future work were given already your were named your research yes but will you still continue the research practice and what will the definite trend your future research yeah thank you for your question is interesting question because see that the area AI study more .well known and important future .to the future because because (erm) there are several several cases where objects (eh) (em) caused the damage for people and. (eh) one any (eh) legal (eh) law system that (eh) decided there this problem the present moment (eh) think is very prospective (eh) practical area well thank you can you also answer the question (eh) you need (eh) several approaches the liability what approach the liability you think should an example for Russian legislation is the first question and then second question about self learning do you think that self learning artificial intelligence should liable for themselves (eh) thank you for your question about approaches (em) there are several years approaches you can you can say and think that the present time single approaches which are decided which decides this problem permanently because (em) think need balanced and complex (eh) approach (eh) decide any cases and ..what else about the second question (eh) think nowadays haven't got general yes self-learning who which function itself but (eh) think (eh) and (eh) several (eh) scientists approved point view that (eh) the legal status legal status (eh).. such self-learning objects can may subject their civil circulation yes ..but think is about thirty forty years maybe more questions thank you 
