Introduction
Background. Nowadays the success of businesses in Telecommunication sector depends on variety of factors. The number of accidents in network is the crucial one, because accidents lead to decrease of clients satisfaction. This fact means, that big number of accidents makes clients choose another company. That is why it is important to control and reduce the number of accidents in optical telecommunication networks for companies who provide these services. 
With data-driven approach companies likely to use analytics and machine learning methods to regulate not only business but technical processes too.
Problem Statement. The aim of the following study is to build Machine Learning model based on data investigation of Telecommunication company to find out what factors impact the number of accidents to understand how to manage the improvement of Telecommunication networks.
The objectives are:
* to determine the factors that could affect the accident;
* to prepare the data; 
* to select the most appropriate methods for building the model;
* to build machine learning models using Python language;
* to draw conclusions based on the obtained results.
Delimitations of the Study. In this study there are literature review to choose appropriate methods, practical part with data preparation and building models, and the conclusion with explanation and interpretation of results.
In the current research I study the number of various methods in order to find an answer to the question: how to find out which factors make the greatest impact on the occurrence of accident in telecommunication network?
Definitions of Key Terms. In order to get a better understanding of the matter, it is important to realize what is the optical telecommunication network and which types of accidents can appear there.
Optical telecommunication network is a system of commutators (nodes) which are connected by fiber optic cables. This network is organized in hierarchy, that is why if one commutator does not work, all dependent devices are not functioning too.
Accident means that the commutator is not working. This can happen by huge number of causes such as electricity disconnection, cable damage, weather, human error. The most frequent one is power outage in a house or porch (it takes about 80% of all accidents). 
Professional Significance. There are some ways how to ease the energy dependence problem. There 'ways' will be used as factors that influence to the number of accidents. However, there is no research about the efficiency of those operations. That is why the most important issue for now is to find out which of existing factors impact on the number of accidents (or to the situation if accident occurred or not). The answer to this problem will help telecommunication companies to prioritize which procedures to use in order to reduce the number of accidents. 
Literature Review
The field of study about the implementation of Machine Learning (ML) methods to different domains has been widely researched. In telecommunication sector, ML is often used for Churn Analysis, Lifetime Value prediction and Recommendation systems. However, there is no information exactly about applying these methods to solve the issue of my work. That is why some existing methods are observed in this article in order to analyze and choose the most relevant strategies for my project. 
As far as I use analytical approach in the project, it is important to understand the connection of statistics and analytics to big data, data science, industrial statistics, statistical thinking, statistical engineering and Six Sigma. All these terms are discussed in. The authors compare the terms of statistics and analytics and show the opportunities of Machine Learning models application to datasets.
In the authors go deeper into statistics and analytics. They compare order statistics and heterogeneous negative binomial variables with applications. The second method is for nontrivial datasets and more relevant for negative binomial distribution. The data scientists investigate stochastic properties of extreme order statistics "arising from independent and heterogeneous negative binomial random variables by exploiting the useful tool of majorization-type and p-larger orders imposed on the distribution parameters". 
While analysts solve the task related to machine learning, they often face the model selection problem. This issue is observed in and. In the second article authors study the existing models, while in the first one they try to create something new.  deals with Model selection and model averaging where the authors use semiparametric partially linear models. Also they work with imputation method in order to describe how to complete the missing data. In model confidence set and Backtest Overfitting are observed. These methods are invented to answer the question "How Hard Is It to Pick the Right Model?" in practice. The authors work with forecasting the financial data task. The idea is that they choose one model and implement it to the same data many times. Since this strategy leads to model overfitting, the scientists use Backtests. Finally, the scientists result that the described method does not solve model selection problem. 
One of the most popular types of machine learning models are regression models because they are relatively simple to use and to interpret. Regression models are used to solve regression, classification, anomaly detection and other supervised learning tasks.  In it is studied how Bernstein polynomials are used in regression analysis for classification and approximation. The authors propose a Bayesian methodology to correct the sample selection bias based on regression semiparametric Bernstein polynomial models. They show the performance of the method on Health Insurance dataset.
It is crucial not only to choose a right model, but also to select features. In variable selection is represented for partially linear model with semiparametric varying coefficient. The chosen model is based on modal regression and shows sufficient performance in cases with missing data. The authors of represent variable selection algorithm for semiparametric varying-coefficient spatial autoregressive models. The proposed machine learning model comprises a diverging number of parameters.
Ensemble methods are widely used to solve machine learning tasks. One of the most popular ensemble method is Random Forest. is also about sample selection, but with Random Forests implementation. The authors investigate semiparametric estimation by comparing truncated and censored regression. Also they study nonparametric method called Kernel regression. In practice, the authors start the algorithm with bootstrapping Monte-Carlo and then use Random Forest. Afterwards they estimate the results with methods mentioned above.
In the authors compare another ensemble method - Rotation Forest to Convolutional Neural Networks by solving classification problem. They highlight the strong and weak aspects of observed methods. In the research they use multisource data for a subtropical forest area. The authors conclude that deep-learning algorithms are not always necessary in order to work with classification task, so classic machine learning models are sufficient in that cases.
The article explains how to analyze stock price with second-order fuzzy time series model. The authors solve the task about stock market data analysis. However, the algorithm is appropriate in other domains, because the problem of fuzzy data is quite common. The scientists build neural networks in their project. Firstly, they prepare data by division them into the number of groups and then apply triangle function to each group. Finally, the authors use back propagation neural network with three hidden layers. The results of the proposed model are quite close with the actual stock prices data, which means that the model shows great performance.
Methods
To start the model creation process, it is necessary to choose the factors that the model will use for learning. Since the task is not typical, it is very important to clearly understand the specifics of the universe of discourse. That is why the first method I am going to use is survey. In particular, I will ask about the features that may influence to the accidents the strongest. Survey of technical department workers and analysis in order to choose the factors for the creating model. After that I am going to collect this data to make the list of features that are appropriate for usage.
For the model building, three different Machine Learning methods will be used. At first, I work with Regression methods, specifically with Logistic regression. It is a Machine Learning algorithm "which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability". Secondly, I implement Ensemble methods using XGBoost library. This is an iterative algorithm which is based on the number of decision trees, and with each iteration the learning model takes into account the errors of its precursors. The third method is Neural Network. The main difference between Neural Network and the previous methods is that this model is self-optimizing and its results cannot be interpreted as usual.
As far as each ML method works with various types of data, it is crucial to prepare relevant data to get good results. To collect and prepare the necessary data, the SQL queries to Database will be used. 
To interpret the results, I will use feature importance method. This is one of feature selection techniques, which is described in details by Raheel Shaikh in. Finally, to choose the best solution that will be implemented in practice I use ordinary comparison method.
Results Anticipated
The result of the project is a Machine Learning model written on Python language, which determines if accident will happen or not and shows the probability of accident in percentage. From the resulting model it should be possible to get the most important information: the answer to the question, which factors influence the number of accidents. This information should look like the ordered list of factors with the given percentage which presents how much does each one impact the model. 
The resulting model should be trained on up-to-date prepared data. The developed algorithm should show high performance on train and test datasets, but it is crucial to avoid overfitting of the model. 
Final factors should be realistic in terms of actual situation on Telecommunication network in analyzed company. Moreover,  it should be possible to make decisions for improving the current situation in company in order to reduce the number of accidents, and these decisions should follow from the resulting list of factors.
Conclusion
This project has high importance for business, because it will help telecommunication companies to save money by costs reduction. The resulting model will show the most influencing factors to the number of accidents with high accuracy. This means, that to reduce the number of accidents, the telecommunication company incorporate some changes to the network organization. Finally, the accidents reduction leads to revenue increase and remains the loyalty of clients.
The algorithm can be modified for different domains and reused and improved in future. In this work I implement Machine Learning algorithms in practice, which will help me to improve my skills and simply solve similar tasks in future. As the next step, I can add new features to the model, train the model on new updated dataset and tune some parameters to rise its performance. 
