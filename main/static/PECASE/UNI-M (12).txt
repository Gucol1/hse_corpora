 can you hear me   yes we can   ok and so hello dear colleagues let me thank you for coming today my name is  I'm a fourth year student from a higher school of economics in Perm and the topic I'm going to discuss is the civil liability of for damage caused by the artificial intelligence next AI and we discussed in detail about issue of differentiation of (eh) AI engineers and operator of civil liability my research is relevant to those who deal with AI issues and start process of digitalization as whole . my research is based on general research methods such as analysis synthesis and comparison and (eh) in interdisciplinary one. the formal legal research method .. so in the slide you can see the main parts of my study (eh) to begin with I will present the background of civil liability for the actions of AI then I formulate the aim and objectives and then demonstrate the sources of the study .after that I will review the basic concepts of AI study (eh) next I will elaborate on the problem of differentiations of AI engineers and operators liability of autonomous systems and finally I will discuss the results and make a conclusion .. though (eh) it's well known fact that the development of high technologies (eh) outpaces legal regulations. in recent decades however these issue have been discussed more often for example the CCRN (eh) journal website published more than 1000 (eh) scientific papers on AI in the last year only .. in twenty seventeen the European Parliament parliament adopted a resolution on civil law on robotics which sets out the main directions and principles for the development of AI despite humanity is at the beginning of the past digitalization and significant objective is the development of legal mechanism to regulate liability for damage caused by AI and one of the main question (eh) is who brings the liability for the actions of AI . to precise an issue (eh) of allocation (eh) of liability between the operator and the AI engineers .. so I will try to answer these questions in my report ... so. in the slide you can see my aim and the objectives I don't comment. it you can see it ... and in this slide you can see my sources of the study (eh) there are divided into international national and foreign (eh) acts and. domestic and foreign doctr legal doctrine (eh) undoubtedly the resolution of your commission (eh) is of particular importance of. for this study taking its provision into account the in August twenty twenty the Russian government approves the concept of the .for the development of a AI technology and robotics until twenty twenty four where one of the main objectives is the issue of AI liability among doctrinal issues sources we can emphasize studies by German . Professor Wagner on liability of AI engineers and Dutch scientists brought to an intent on the liability of the operator so . having analyzed scientific papers (eh) of various legal scholars AI can be defined as a technology that has a certain degree of autonomy autonomy and is able to perform (eh) or to precise imitate rational actions like human beings it usually can self learn (eh) and may have (eh) material shell for example (eh) in the form (eh) of a robot (eh) so there is a debate in doctrine (eh) concerning in the legal personality (eh) of AI we believe that is an object of circulation (erm) at the present time but we cannot ignore that fact that AI may become cozy subject in the near future in particular this position is held by the researchers  and others ... so (eh) Israel professor  in the defiant four types of subjects of liability for the actions of AI the manufacture the same the AI engineer the operator the distributor and the end user professor  proposes the sponsor of AI research as a subject of liability based on act on the South Korean law on smart robots and professor  also supplements this list by the owner and possessor but overall this list the subject is not executive exhaustive (eh) according to the (eh) euro commission's resolution . so nevertheless in particular situations it is important to identify (eh) those person who should be held liable for this actions of the AI (em) . so speaking of approaches to civil (eh) liability for the actions different approaches are distinguished depending on the classification. professor Smith and Neznamov distinguished seven types of liability based on degree of culpability for such  and  suggest that liability of A I should be considered through the concept of legal person and however we decided to stop the classification based on the responsibility of a subject of responsibility here  engineers while the researchers brought John Linton highlight the liability of apparatus as a separate subject so in the following we look at the basis for the allocation of development operator liability so professor  defines that AI developer as a person who has taken part in the development or production of autonomous systems including software developers the scientists believe that developer is only person who is able to minimize. the risk because they are responsible for implementing precautions in the use of  autonomous device and have more information than consumers based on the European Commission Directive on Product Liability they also points out that in article for the burden of proving a defect lies with the consumer in the case of AI these allegations of the burden of proof seems unacceptable because it would be more difficult for the consumers to prove (eh) a defect in specific products such as AI as they do not have their current information about the object thus if the consumer will not able to cope with that burden of proof that also proposed to shift its it to the AI developer .there is also the position that no fault liability also known as a strict liability should be applied (eh) to the developer (eh). so the developer would be liable for any damages other than guilty acts of the consumer. in our view the abrupt shifts of such approach would destroy the entire scientific and technical potential of AI system a development of the object of discussion has been (eh) the imposition of liability on the operator .and that scientist  defined the operator as the person who provides updates and support services to the autonomous device on a regular basis so they are responsible for teaching the autonomous system so they are informally called the teacher the first challenges that arise here is what to extend the teacher liable (eh) for opposed to the AI engineer it is logical to us to differentiate the liability by establishing (eh) the obligation of the former and the latter in legal act or a contract however it possible that developer and teacher may be the same person (eh) in the case (eh) it wants to distinguish liability for. designing the AI system from one of it the second issue is the distinguish between strict and limited liability scientists believe that strict liability is applicable to the situation where the amount damages caused significant to the objects operate and public spaces has and has a high degree of autonomy .in cases of AI treatment system for autism for example the amount of potential damage is not significant and it is controlled by operator so it would it wouldn't (eh) be appropriate to apply strict liability to a teacher in particular situation however even in this case where damage caused is due to a defect (eh) in the system itself strict liability is permissible and those the A I engineers and teachers liability are similar at the first site but the engineers areas of liability is wider and consequently a stricter standard of liability should be applied to them as they at least have more information about the products on the other hand in the situation where the AI systems are evolving it's important not to create unnecessary legal barriers to the development of such system so the application of a strict liability should be reasonable justified. and the last one teacher. liability a separate subject is applicable in situations where A I does not have a high degree of autonomy however the issue of the liability of a self-loading AI whose actions beyond the control of the AI engineers and the teacher remains unexplored. all things considered while AI systems continue to evolve it is important to bear in mind the development of law in order to provide ways of minimizing the potential damage that new technologies can cause so thank you for your attention I look forward answering your questions   so dear participants you are welcome with your questions ... so  (eh) the prospects for the prospects of your future work were given already in your so were named in your research yes but will you still continue the research in practice and what will be the definite trend of your future research   yeah thank you for your question it is interesting question because I see that the area of AI study is a more .well known and important to future .to the future because because (erm) there are several several cases where AI objects (eh) (em) caused the damage for people and. (eh) no one any (eh) legal (eh) law system that (eh) decided there is this problem at the present moment (eh) so I think it is very prospective (eh) practical area   well thank you    can you also answer the question (eh) you need (eh) several approaches to the liability so what approach to the liability do you think should be an example for Russian legislation it is the  first question and then second question is about self learning AI do you think that self learning artificial intelligence should be liable for themselves  (eh) ok thank you for your question . so about approaches (em) there are several years approaches as you can as you can say and I think that at the present time no single approaches which are . decided which decides this problem permanently because (em) I think we need a balanced and complex (eh) approach to (eh) decide any cases and ..what else about the second question (eh) I think nowadays we haven't got general AI yes self-learning AI who which function itself but (eh) I think (eh)  and (eh) several (eh) scientists approved my point of view that (eh) the legal status legal status of (eh).. such as self-learning AI objects can be   may be subject of their civil circulation yes ..but I think it is about thirty or forty years maybe   no more questions  thank you 
